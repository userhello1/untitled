# ðŸš€ GUIDE KAFKA - COMMUNICATION ASYNCHRONE

## ðŸ“š RÃ‰SUMÃ‰ DES CONCEPTS

### **Qu'est-ce que Kafka ?**
Kafka est un systÃ¨me de **messagerie distribuÃ©** qui permet aux microservices de communiquer de maniÃ¨re **asynchrone** via des **Ã©vÃ©nements**.

### **DiffÃ©rence SYNCHRONE vs ASYNCHRONE**

#### SYNCHRONE (REST/Feign) :
```
Service A â†’ REST â†’ Service B â†’ Attend la rÃ©ponse â†’ Continue
           |------ BloquÃ© ici ------|
```
- âœ… Simple Ã  comprendre
- âœ… RÃ©ponse immÃ©diate
- âŒ Couplage fort (Service A dÃ©pend de Service B)
- âŒ Lent si plusieurs appels
- âŒ Si Service B est down, Service A Ã©choue

#### ASYNCHRONE (Kafka) :
```
Service A â†’ Kafka â†’ Continue immÃ©diatement
               â†“
         Service B (Ã©coute et traite en arriÃ¨re-plan)
         Service C (Ã©coute et traite en arriÃ¨re-plan)
         Service D (Ã©coute et traite en arriÃ¨re-plan)
```
- âœ… DÃ©couplage (Service A ne connaÃ®t pas B, C, D)
- âœ… Rapide (pas d'attente)
- âœ… RÃ©silient (si B est down, A continue)
- âœ… Scalable (facile d'ajouter Service E, F, G...)
- âŒ Plus complexe Ã  mettre en place

---

## ðŸ—ï¸ ARCHITECTURE MISE EN PLACE

### **Composants crÃ©Ã©s :**

1. **`docker-compose.yml`** â†’ Infrastructure Kafka
   - Zookeeper (coordination)
   - Kafka Broker (serveur de messages)

2. **`BillCreatedEvent`** â†’ L'Ã©vÃ©nement publiÃ©
   - billId, customerId, customerName, customerEmail
   - billingDate, totalItems, totalAmount

3. **`application.properties`** â†’ Configuration Kafka
   - Producer config (sÃ©rialiseurs, bootstrap servers)
   - Consumer config (dÃ©sÃ©rialiseurs, group ID)

4. **`BillEventProducer`** â†’ Publie les Ã©vÃ©nements
   - Utilise KafkaTemplate
   - Envoie sur le topic "bill-created-topic"

5. **`BillEventConsumer`** â†’ Ã‰coute les Ã©vÃ©nements
   - @KafkaListener sur "bill-created-topic"
   - Traite les Ã©vÃ©nements (log, email, stats...)

6. **`BillingRestController`** â†’ ModifiÃ©
   - CrÃ©e la facture (SYNCHRONE)
   - Publie l'Ã©vÃ©nement (ASYNCHRONE)
   - Retourne la rÃ©ponse HTTP

### **Flux complet :**

```
1. POST /api/bills/customer/1
              â†“
2. BillingRestController
   - RÃ©cupÃ¨re customer via Feign (SYNCHRONE)
   - CrÃ©e Bill + ProductItems en BDD
   - Construit BillCreatedEvent
              â†“
3. BillEventProducer.sendBillCreatedEvent()
   - SÃ©rialise en JSON
   - Envoie Ã  Kafka
              â†“
4. Kafka Broker
   - Stocke le message dans "bill-created-topic"
   - Distribue aux consommateurs
              â†“
5. BillEventConsumer.consumeBillCreatedEvent()
   - DÃ©sÃ©rialise le JSON
   - Traite l'Ã©vÃ©nement (log, email, etc.)
              â†“
6. Autres services potentiels
   - NotificationService (envoie email)
   - AnalyticsService (met Ã  jour stats)
   - AccountingService (enregistre en compta)
```

---

## ðŸ§ª COMMENT TESTER

### **Ã‰tape 1 : DÃ©marrer Kafka**

```powershell
# Dans le rÃ©pertoire racine (oÃ¹ se trouve docker-compose.yml)
docker-compose up -d

# VÃ©rifier que Kafka est dÃ©marrÃ©
docker-compose ps

# Voir les logs
docker-compose logs -f kafka
```

**Ports utilisÃ©s :**
- Zookeeper : `2181`
- Kafka : `9092`

---

### **Ã‰tape 2 : DÃ©marrer les microservices**

Dans cet ordre :

1. **Discovery Service** (port 8761)
   ```powershell
   cd discovery-service
   mvn spring-boot:run
   ```

2. **Customer Service** (port 8081)
   ```powershell
   cd customer-service
   mvn spring-boot:run
   ```

3. **Inventory Service** (port 8082)
   ```powershell
   cd inventoryService
   mvn spring-boot:run
   ```

4. **Billing Service** (port 8083)
   ```powershell
   cd billing-service
   mvn spring-boot:run
   ```

5. **Gateway** (port 8888) - Optionnel
   ```powershell
   cd gateway
   mvn spring-boot:run
   ```

---

### **Ã‰tape 3 : CrÃ©er une facture et observer Kafka**

#### **CrÃ©er une facture via REST :**

```http
POST http://localhost:8083/api/bills/customer/1
```

Ou via PowerShell :
```powershell
Invoke-RestMethod -Uri "http://localhost:8083/api/bills/customer/1" -Method Post
```

#### **Observer les logs du billing-service :**

Vous devriez voir :

```
========================================
ðŸ“¤ KAFKA PRODUCER: Publication d'un Ã©vÃ©nement
   â†’ Topic: bill-created-topic
   â†’ Key (billId): 1
   â†’ Customer: John Doe (john@example.com)
   â†’ Date: Sat Nov 23 2025 10:30:00
   â†’ Total items: 25
   â†’ Total amount: 1250.5 â‚¬
========================================
âœ… Ã‰vÃ©nement envoyÃ© avec succÃ¨s Ã  Kafka !
========================================

[Quelques millisecondes aprÃ¨s...]

========================================
ðŸ“¥ KAFKA CONSUMER: Ã‰vÃ©nement reÃ§u !
   â†’ Topic: bill-created-topic
   â†’ Consumer Group: billing-group
========================================
ðŸ“„ DÃ‰TAILS DE LA FACTURE:
   â†’ Bill ID: 1
   â†’ Customer ID: 1
   â†’ Customer Name: John Doe
   â†’ Customer Email: john@example.com
   â†’ Billing Date: Sat Nov 23 2025 10:30:00
   â†’ Total Items: 25
   â†’ Total Amount: 1250.5 â‚¬
========================================
ðŸ“§ Envoi d'un email de confirmation Ã  john@example.com
ðŸ“Š Mise Ã  jour des statistiques de facturation
ðŸ”” Envoi d'une notification push au client
ðŸ“¦ Archivage de la facture pour la comptabilitÃ©
ðŸ“ Enregistrement dans le journal d'audit
âœ… Ã‰vÃ©nement traitÃ© avec succÃ¨s !
========================================
```

---

### **Ã‰tape 4 : VÃ©rifier Kafka (Optionnel)**

#### **Lister les topics :**
```powershell
docker exec -it kafka-broker kafka-topics --list --bootstrap-server localhost:9092
```

Vous devriez voir : `bill-created-topic`

#### **Lire les messages du topic :**
```powershell
docker exec -it kafka-broker kafka-console-consumer --topic bill-created-topic --from-beginning --bootstrap-server localhost:9092
```

Vous verrez les Ã©vÃ©nements au format JSON :
```json
{
  "billId": 1,
  "customerId": 1,
  "customerName": "John Doe",
  "customerEmail": "john@example.com",
  "billingDate": 1700736600000,
  "totalItems": 25,
  "totalAmount": 1250.5
}
```

---

## ðŸ”„ TESTER AVEC PLUSIEURS FACTURES

```powershell
# CrÃ©er plusieurs factures
Invoke-RestMethod -Uri "http://localhost:8083/api/bills/customer/1" -Method Post
Invoke-RestMethod -Uri "http://localhost:8083/api/bills/customer/2" -Method Post
Invoke-RestMethod -Uri "http://localhost:8083/api/bills/customer/3" -Method Post
```

Observez les logs : vous verrez 3 Ã©vÃ©nements publiÃ©s et consommÃ©s !

---

## ðŸ“Š VÃ‰RIFIER LES FACTURES EN BASE

```http
GET http://localhost:8083/api/bills
```

Ou :
```powershell
Invoke-RestMethod -Uri "http://localhost:8083/api/bills"
```

---

## ðŸ› ï¸ CONCEPTS AVANCÃ‰S

### **Consumer Groups**

Dans `application.properties`, on a dÃ©fini `spring.kafka.consumer.group-id=billing-group`.

**Qu'est-ce qu'un Consumer Group ?**
- Les consommateurs du **mÃªme groupe** se **partagent** les messages (load balancing)
- Les consommateurs de **groupes diffÃ©rents** reÃ§oivent **tous** les messages (broadcast)

**Exemple :**

```
Topic: bill-created-topic (3 partitions)

Consumer Group A (billing-group):
  - Consumer A1 lit: Partition 0, 1
  - Consumer A2 lit: Partition 2

Consumer Group B (notification-group):
  - Consumer B1 lit: Partition 0, 1, 2

RÃ©sultat:
- Dans le groupe A, chaque message va Ã  1 seul consumer (load balancing)
- Le groupe B reÃ§oit AUSSI tous les messages (broadcast)
```

**Cas d'usage :**
- `billing-group` : Traite la facture (1 seul consumer doit le faire)
- `notification-group` : Envoie email (sÃ©parÃ©, peut Ã©chouer indÃ©pendamment)
- `analytics-group` : Met Ã  jour stats (sÃ©parÃ©, peut Ã©chouer indÃ©pendamment)

---

### **Partitions et Ordre des Messages**

Dans `docker-compose.yml`, on a configurÃ© 3 partitions par dÃ©faut.

**Ã€ quoi servent les partitions ?**
1. **ParallÃ©lisme** : Plusieurs consumers peuvent lire en parallÃ¨le
2. **Ordre garanti** : Messages avec la mÃªme clÃ© vont dans la mÃªme partition

**Exemple :**

```
Topic: bill-created-topic (3 partitions)

Message 1 (billId=1) â†’ hash(1) % 3 = Partition 1
Message 2 (billId=2) â†’ hash(2) % 3 = Partition 2
Message 3 (billId=3) â†’ hash(3) % 3 = Partition 0
Message 4 (billId=1) â†’ hash(1) % 3 = Partition 1 (mÃªme partition que Message 1 !)

RÃ©sultat:
- Tous les Ã©vÃ©nements de la facture #1 sont dans la Partition 1
- L'ordre est garanti pour la facture #1
- Les factures diffÃ©rentes peuvent Ãªtre traitÃ©es en parallÃ¨le
```

---

### **RÃ©tention des Messages**

Dans `docker-compose.yml`, on a configurÃ© `KAFKA_LOG_RETENTION_MS: 604800000` (7 jours).

**Que se passe-t-il aprÃ¨s 7 jours ?**
- Les anciens messages sont automatiquement supprimÃ©s
- Les nouveaux consumers ne voient pas les messages de plus de 7 jours
- En production, ajustez selon vos besoins (1 jour, 30 jours, infini...)

---

### **Offsets**

**C'est quoi un offset ?**
- Position de lecture dans une partition (comme un marque-page)
- Kafka se souvient oÃ¹ chaque consumer group a lu

**Exemple :**

```
Partition 0: [Msg0, Msg1, Msg2, Msg3, Msg4, Msg5]
                                    â†‘
                        billing-group offset = 3
                        (a lu jusqu'Ã  Msg3, prochain = Msg4)
```

**Si le consumer redÃ©marre :**
- Il reprend Ã  l'offset 3 (Msg4)
- Il ne relit pas les anciens messages dÃ©jÃ  traitÃ©s
- C'est la magie de `auto-commit` !

**Auto-offset-reset:**
- `earliest` : Si aucun offset, lit depuis le dÃ©but
- `latest` : Si aucun offset, lit uniquement les nouveaux
- `none` : Si aucun offset, erreur

---

## ðŸŽ¯ EXERCICES PRATIQUES

### **Exercice 1 : Ajouter un champ Ã  l'Ã©vÃ©nement**

1. Ajoutez un champ `status` dans `BillCreatedEvent`
2. Modifiez le `BillingRestController` pour le remplir
3. Modifiez le `BillEventConsumer` pour l'afficher

### **Exercice 2 : CrÃ©er un nouveau Consumer**

1. CrÃ©ez un nouveau service (ex: `notification-service`)
2. Ajoutez la dÃ©pendance Kafka
3. CrÃ©ez un `@KafkaListener` avec un `groupId` diffÃ©rent
4. Testez : les 2 consumers doivent recevoir le mÃªme Ã©vÃ©nement !

### **Exercice 3 : Filtrer les Ã©vÃ©nements**

Dans `BillEventConsumer`, traitez uniquement les factures > 500â‚¬ :

```java
@KafkaListener(topics = "bill-created-topic", groupId = "billing-group")
public void consumeBillCreatedEvent(BillCreatedEvent event) {
    if (event.getTotalAmount() < 500) {
        log.info("â­ï¸ Facture ignorÃ©e (montant trop faible)");
        return;
    }
    // Traiter uniquement les grandes factures
}
```

### **Exercice 4 : CrÃ©er un nouvel Ã©vÃ©nement**

CrÃ©ez un Ã©vÃ©nement `BillPaidEvent` qui est publiÃ© quand une facture est payÃ©e :

1. CrÃ©er `BillPaidEvent.java`
2. CrÃ©er un endpoint `POST /api/bills/{id}/pay`
3. Publier l'Ã©vÃ©nement dans le endpoint
4. CrÃ©er un consumer qui rÃ©agit Ã  cet Ã©vÃ©nement

---

## ðŸ§¹ NETTOYAGE

### **ArrÃªter Kafka :**
```powershell
docker-compose down
```

### **Supprimer les donnÃ©es Kafka :**
```powershell
docker-compose down -v
```

---

## ðŸŽ“ CONCEPTS CLÃ‰ Ã€ RETENIR

1. **Kafka = Communication asynchrone** entre microservices
2. **Producer** = Publie des Ã©vÃ©nements
3. **Consumer** = Ã‰coute et traite des Ã©vÃ©nements
4. **Topic** = Canal de communication
5. **Partition** = Division d'un topic (parallÃ©lisme + ordre)
6. **Consumer Group** = Groupe de consumers (load balancing)
7. **Offset** = Position de lecture (comme un marque-page)
8. **Asynchrone = Rapide + DÃ©couplÃ© + RÃ©silient**

---

## ðŸ“– POUR ALLER PLUS LOIN

- **Kafka Streams** : Traitement de flux en temps rÃ©el
- **Kafka Connect** : IntÃ©gration avec bases de donnÃ©es
- **Schema Registry** : Gestion des schÃ©mas Avro/Protobuf
- **KSQL** : SQL pour interroger les streams Kafka
- **Dead Letter Topics** : Gestion des messages en erreur
- **Idempotence** : Ã‰viter les doublons de messages
- **Exactly-once semantics** : Garantie de traitement unique

---

## ðŸ†˜ DÃ‰PANNAGE

### **Erreur: Connection refused (Kafka)**
â†’ VÃ©rifiez que Docker est dÃ©marrÃ© : `docker ps`

### **Erreur: Topic does not exist**
â†’ Kafka crÃ©e automatiquement les topics, attendez quelques secondes

### **Le consumer ne reÃ§oit pas les messages**
â†’ VÃ©rifiez le `group-id` et `auto-offset-reset` dans application.properties

### **Les messages sont dupliquÃ©s**
â†’ DÃ©sactivez `auto-commit` et commitez manuellement

### **Kafka est lent**
â†’ Augmentez le nombre de partitions
â†’ Ajoutez plus de consumers (1 par partition max)

---

**ðŸŽ‰ FÃ©licitations ! Vous avez implÃ©mentÃ© Kafka avec succÃ¨s ! ðŸŽ‰**
